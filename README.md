# ğŸ§¾ Analyse des marchÃ©s publics et dÃ©tection d'anomalies

**Projet de Data Science â€“ Bootcamp Le Wagon, Batch #1992** 

---

## ğŸ¯ Objectifs

- **Renforcer la transparence** dans la commande publique
- **Aider les collectivitÃ©s** Ã  mieux estimer les montants de leurs futurs marchÃ©s  
- **Identifier les comportements atypiques** (voire suspects) dans les donnÃ©es ouvertes des marchÃ©s publics (donnÃ©es DECP)
- **En bonus** : faciliter l'exploration des donnÃ©es via un chatbot basÃ© sur la technologie RAG

---

## ğŸ”§ Modules du projet

### ğŸ”¹ Module 1 â€“ Estimation des montants de marchÃ© (fourchettes)
**ğŸ” Objectif** : PrÃ©dire une tranche rÃ©aliste de montant pour un nouveau marchÃ© public

**ğŸ¯ Pourquoi** : Aider les collectivitÃ©s Ã  anticiper leurs dÃ©penses et Ã  prÃ©venir les surcoÃ»ts

**ğŸ” DÃ©fi** : Les codes CPV sont parfois trop larges â†’ une prÃ©diction exacte est illusoire

**âœ… Solution** :
- Transformation du problÃ¨me en classification (fourchettes de montant)
- **ModÃ¨les testÃ©s** : XGBoost, Random Forest, SVM
- **Feature engineering** sur les colonnes CPV, procÃ©dure, localisation, acheteur, texte rÃ©sumÃ©...

### ğŸ”¹ Module 2 â€“ Recherche de marchÃ©s similaires (clustering & matching)
**ğŸ” Objectif** : Trouver les 10 marchÃ©s passÃ©s les plus proches d'un marchÃ© donnÃ©

**ğŸ¯ Pourquoi** : Aider une collectivitÃ© Ã  se comparer Ã  des marchÃ©s dÃ©jÃ  rÃ©alisÃ©s

**âœ… Approches** :
- Vectorisation des marchÃ©s (TF-IDF sur la description, features numÃ©riques)
- Clustering (KMeans, DBSCAN) + recherche de proximitÃ© (NearestNeighbors)
- Moteur de similaritÃ© utilisable dans l'interface Streamlit

### ğŸ”¹ Module 3 â€“ DÃ©tection d'anomalies dans les marchÃ©s publics
**ğŸ” Objectif** : RepÃ©rer les marchÃ©s anormaux dans la base (montants suspects, comportements hors normes)

**ğŸ¯ Pourquoi** : Lutter contre les dÃ©rives (clientÃ©lisme, favoritisme, entente)

**âœ… MÃ©thodes** :
- **Isolation Forest** : analyse non supervisÃ©e pour repÃ©rer les points rares
- **DBSCAN** : identifie les marchÃ©s hors des clusters denses â†’ signal d'alerte
- **Visualisation** des marchÃ©s atypiques avec rÃ©duction de dimension (UMAP, t-SNE)
- **Test de GNN** (Graph Neural Network) pour analyser les relations acheteurs-fournisseurs comme un graphe : les communautÃ©s isolÃ©es ou trop denses peuvent signaler des comportements suspects

### ğŸ§  Module 4 (optionnel) â€“ Interface RAG & exploration conversationnelle
**ğŸ” Objectif** : Permettre Ã  un utilisateur de poser des questions naturelles sur la base

**Exemple** : *"Quels sont les marchÃ©s de cybersÃ©curitÃ© passÃ©s en 2023 dans le 69 ?"*

**ğŸ§° Stack** :
- LangChain, FAISS, embeddings open-source
- Construction d'un index vectoriel des rÃ©sumÃ©s de marchÃ©
- Agent simple (ou chatbot) pour rÃ©pondre aux requÃªtes de type : mots-clÃ©s, dÃ©partement, procÃ©dure, fourchette, etc.

---

## ğŸ–¥ï¸ Interface utilisateur (Streamlit)

Une app simple avec 3 Ã  4 pages :
- **Estimation** d'un montant pour un nouveau marchÃ©
- **Suggestion** de marchÃ©s similaires  
- **DÃ©tection** d'anomalies
- **(Bonus)** Chatbot exploratoire pour naviguer dans la base

---

## ğŸ“ DonnÃ©es

- **Source** : DonnÃ©es ouvertes DECP (data.gouv.fr)
- **Ã‰tat** : DÃ©jÃ  prÃ©traitÃ©es (normalisation, nettoyage) + schÃ©ma de base structurÃ©
- **Variables utilisÃ©es** : intitulÃ©, description, acheteur, fournisseur, CPV, procÃ©dure, date, montant, localisation...

---

## ğŸ§° Stack technique

- **Langage** : Python 3.9+
- **ML/Data** : `pandas`, `scikit-learn`, `xgboost`, `matplotlib`, `seaborn`
- **Clustering** : `scikit-learn`, `umap-learn`
- **Anomalies** : `isolation-forest`, `dbscan`
- **RAG** : `langchain`, `faiss-cpu`, `sentence-transformers`
- **Interface** : `streamlit`
- **Infrastructure** : Docker, Docker Compose

---

## ğŸš€ Installation et lancement

### ğŸ“‹ PrÃ©requis

- **Python 3.10.6** via [pyenv](https://github.com/pyenv/pyenv)
- **Git**
- **Docker** et **Docker Compose** (optionnel)

### ğŸ Installation avec pyenv (recommandÃ©)

```bash
# Cloner le dÃ©pÃ´t
# Se positionner dans le dossier souhaitÃ© dans le terminal
git clone https://github.com/RonanB400/decp_ml.git
cd decp_ml

# Installer Python 3.10.6 avec pyenv (si pas dÃ©jÃ  fait)
pyenv install 3.10.6

# CrÃ©er et activer votre environnement virtuel
pyenv virtualenv 3.10.6 decp_ml_env
pyenv local decp_ml_env

# Installer les dÃ©pendances
pip install --upgrade pip
pip install -r requirements.txt
```

### ğŸ” Configuration des variables d'environnement

```bash
# Copier le fichier d'exemple des variables d'environnement
cp .env.example .env

# Ã‰diter le fichier .env avec vos clÃ©s API
nano .env  # ou votre Ã©diteur prÃ©fÃ©rÃ©

# (Optionnel) Si vous utilisez direnv pour l'auto-chargement
cp .envrc.example .envrc
direnv allow
```

### ğŸš€ Lancement de l'application

```bash
# Lancer l'application Streamlit
streamlit run app/main.py

# L'application sera accessible sur http://localhost:8501
```

### ğŸ³ Installation avec Docker (alternative)

```bash
# Construire et lancer les containers
docker-compose up --build

# L'application sera accessible sur http://localhost:8501
# Jupyter Lab sera accessible sur http://localhost:8888
```

---

## ğŸ“ Structure du projet

```
decp_ml/
â”œâ”€â”€ ğŸ“‚ data/                    # DonnÃ©es sources (SQLite, CSV)
â”‚   â”œâ”€â”€ decp.sqlite            # Base DECP principale
â”‚   â””â”€â”€ datalab.sqlite         # Base traitÃ©e
â”œâ”€â”€ ğŸ“‚ notebooks/              # Analyses exploratoires
â”œâ”€â”€ ğŸ“‚ src/                    # Code source principal
â”‚   â”œâ”€â”€ ğŸ“‚ estimation/         # Module 1: Estimation montants
â”‚   â”œâ”€â”€ ğŸ“‚ clustering/         # Module 2: MarchÃ©s similaires  
â”‚   â”œâ”€â”€ ğŸ“‚ anomalies/          # Module 3: DÃ©tection anomalies
â”‚   â””â”€â”€ ğŸ“‚ rag/               # Module 4: Interface RAG
â”œâ”€â”€ ğŸ“‚ models/                 # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”‚   â”œâ”€â”€ ğŸ“‚ estimation/
â”‚   â”œâ”€â”€ ğŸ“‚ clustering/
â”‚   â””â”€â”€ ğŸ“‚ anomalies/
â”œâ”€â”€ ğŸ“‚ app/                    # Interface Streamlit
â”‚   â”œâ”€â”€ ğŸ“‚ pages/             # Pages de l'application
â”‚   â”œâ”€â”€ ğŸ“‚ components/        # Composants rÃ©utilisables
â”‚   â””â”€â”€ ğŸ“‚ utils/             # Utilitaires interface
â”œâ”€â”€ ğŸ“‚ tests/                  # Tests unitaires
â”œâ”€â”€ ğŸ“‚ docs/                   # Documentation
â”œâ”€â”€ ğŸ“‚ config/                 # Fichiers de configuration
â”œâ”€â”€ ğŸ“‚ scripts/                # Scripts utilitaires
â”œâ”€â”€ .env.example               # Template des variables d'environnement
â”œâ”€â”€ .envrc.example             # Template direnv (optionnel)
â”œâ”€â”€ .python-version            # Version Python pour pyenv
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml         # Configuration Docker
â”œâ”€â”€ Dockerfile                 # Image Docker
â””â”€â”€ README.md                  # Ce fichier
```

---

## ğŸ“– Explication dÃ©taillÃ©e de la structure

### ğŸ¯ **Dossiers principaux**

#### ğŸ“‚ **`src/`** - Code source principal
- **`src/estimation/`** - Module 1 : Estimation des montants (Personne 1)
  - Classification par fourchettes de montants
  - Feature engineering sur CPV, procÃ©dure, localisation
  - ModÃ¨les : XGBoost, Random Forest, SVM

- **`src/clustering/`** - Module 2 : Recherche de marchÃ©s similaires (Personne 2)
  - Vectorisation TF-IDF des descriptions
  - Clustering KMeans, DBSCAN
  - Moteur de recherche de proximitÃ©

- **`src/anomalies/`** - Module 3 : DÃ©tection d'anomalies (Personnes 3 & 4)
  - Isolation Forest pour dÃ©tecter les points rares
  - DBSCAN pour identifier les outliers
  - GNN pour analyser les relations acheteurs-fournisseurs
  - Visualisation avec UMAP, t-SNE

- **`src/rag/`** - Module 4 : Interface RAG (optionnel)
  - Indexation vectorielle avec FAISS
  - LangChain pour les requÃªtes en langage naturel
  - Embeddings des descriptions de marchÃ©s

#### ğŸ“‚ **`app/`** - Interface utilisateur Streamlit
- **`app/main.py`** - Application principale avec navigation entre modules
- **`app/pages/`** - Pages spÃ©cifiques (estimation, clustering, anomalies, RAG)
- **`app/components/`** - Composants rÃ©utilisables (graphiques, widgets, formulaires)
- **`app/utils/`** - Utilitaires pour l'interface (helpers, formatage)

#### ğŸ“‚ **`models/`** - ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
- **`models/estimation/`** - ModÃ¨les de classification des montants (.pkl, .joblib)
- **`models/clustering/`** - ModÃ¨les de clustering et vectoriseurs
- **`models/anomalies/`** - ModÃ¨les de dÃ©tection d'anomalies

### ğŸ”§ **Dossiers de support**

#### ğŸ“‚ **`data/`** - DonnÃ©es (existant)
- **`datalab.sqlite`** - Base de donnÃ©es traitÃ©e
- **`processed/`** - DonnÃ©es preprocessÃ©es pour chaque module

#### ğŸ“‚ **`config/`** - Configuration
- **`config.yaml`** - ParamÃ¨tres centralisÃ©s (seuils, chemins, hyperparamÃ¨tres)
- Configuration des modÃ¨les, RAG, interface Streamlit

#### ğŸ“‚ **`notebooks/`** - Analyses exploratoires
(ajoutez vos initiales dans le nom de vos notebooks)
- Notebooks Jupyter pour l'exploration des donnÃ©es
- Prototypage des modÃ¨les
- Analyses statistiques et visualisations

#### ğŸ“‚ **`tests/`** - Tests unitaires
- Tests pour valider chaque module
- Tests d'intÃ©gration de l'interface
- Validation des modÃ¨les

#### ğŸ“‚ **`docs/`** - Documentation
- Documentation technique dÃ©taillÃ©e
- Guides utilisateur
- Rapports d'analyse
- Images, logos pour l'interface
- Fichiers CSS personnalisÃ©s
- SchÃ©mas et diagrammes

#### ğŸ“‚ **`scripts/`** - Scripts utilitaires
- Scripts de preprocessing des donnÃ©es
- Scripts de dÃ©ploiement
- Utilitaires de maintenance


### âš™ï¸ **Fichiers de configuration**

- **`requirements.txt`** - DÃ©pendances Python avec versions spÃ©cifiques
- **`Dockerfile`** - Image Docker pour conteneurisation
- **`docker-compose.yml`** - Orchestration des services (app + jupyter)
- **`.env.example`** - Template des variables d'environnement (clÃ©s API, secrets)
- **`.envrc.example`** - Template direnv pour auto-chargement des variables
- **`.python-version`** - Version Python fixÃ©e pour pyenv
- **`README.md`** - Documentation principale du projet

### ğŸ” **Gestion des secrets et variables d'environnement**

#### Variables d'environnement nÃ©cessaires :
```bash
# API Keys (exemples)
OPENAI_API_KEY=sk-...                    # Pour le module RAG
HUGGINGFACE_API_TOKEN=hf_...             # Pour les embeddings
STREAMLIT_SECRET_KEY=your-secret-key     # Pour les sessions Streamlit

# Configuration base de donnÃ©es
DATABASE_URL=sqlite:///data/datalab.sqlite  # Chemin vers la base DECP
LOG_LEVEL=INFO                           # Niveau de logging

# Configuration modÃ¨les
MODEL_CACHE_DIR=./models                 # Dossier de cache des modÃ¨les
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

#### Fichiers Ã  ne PAS commiter :
- **`.env`** - Variables personnelles (ajoutÃ© au .gitignore)
- **`.envrc`** - Configuration direnv personnelle (ajoutÃ© au .gitignore)
- **`models/*.pkl`** - ModÃ¨les entraÃ®nÃ©s volumineux

### ğŸš€ **Workflow de dÃ©veloppement**

1. **DÃ©veloppement** : Chaque personne code dans son module `src/`
2. **Tests** : CrÃ©ation de tests unitaires dans `tests/`
3. **Sauvegarde** : ModÃ¨les entraÃ®nÃ©s dans `models/`
4. **Documentation** : Ajout de docs dans `docs/`
5. **IntÃ©gration** : Interface commune dans `app/`
6. **DÃ©ploiement** : Via Docker avec `docker-compose up`


---

## ğŸ“Œ Livrables attendus

- âœ… Scripts de preprocessing et feature engineering
- âœ… ModÃ¨les entraÃ®nÃ©s et sauvegardÃ©s (`.pkl`, `.joblib`)
- âœ… Base vectorielle et index FAISS (pour RAG)
- âœ… Application Web interactive (Streamlit)
- âœ… Documentation technique et guide utilisateur
- âœ… Tests unitaires et validation des modÃ¨les
- âœ… Rapport d'analyse et recommandations

---


