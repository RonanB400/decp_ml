{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc5601fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from keras import Sequential, layers, Input, regularizers\n",
    "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3f68ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/data_clean.csv')\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e17049f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.data_cleaner import filter_top_cpv_categories\n",
    "\n",
    "# df = filter_top_cpv_categories(df, top_n=150, cpv_column='codeCPV_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "99970bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['codeCPV_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b87cc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df[df['montant'] > 999999].index, inplace=True)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e48e4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.log1p(df['montant'])\n",
    "# y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fe95605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linspace(y.min(), y.max(), 10)\n",
    "# bins = np.delete(bins, 1)\n",
    "\n",
    "# #bins = bins[2:]\n",
    "\n",
    "# # Créer les étiquettes correspondantes\n",
    "# labels = list(range(1, len(bins)))\n",
    "\n",
    "# # Ajouter la colonne fourchette_de_prix\n",
    "# df['bins'] = pd.cut(y, bins=bins, labels=labels, include_lowest=True, right=True)\n",
    "\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "05193634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  20001.        ,   47708.50133762,   73683.08597334,\n",
       "        113799.36502582,  175756.69245133,  271446.28561345,\n",
       "        419233.45817256,  647482.39989405, 1000000.        ])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f77926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['bins'] = df['bins'].astype('int')\n",
    "# df = df.drop(columns='montant')\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fecaaae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop(columns=['bins', 'titulaire_tranche_effectif', 'titulaire_categorie'])\n",
    "# y = df['bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "42475c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[['acheteur_tranche_effectif', 'acheteur_categorie']] = X[['acheteur_tranche_effectif', 'acheteur_categorie']].fillna('null')\n",
    "# X[['acheteur_tranche_effectif', 'acheteur_categorie']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa7b392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=0, stratify=X['codeCPV_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3eff487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.preprocess_pipeline import create_pipeline\n",
    "\n",
    "# numerical_columns = ['dureeMois', 'offresRecues', 'annee']\n",
    "\n",
    "# binary_columns = ['sousTraitanceDeclaree', 'origineFrance',\n",
    "#                           'marcheInnovant', 'idAccordCadre']\n",
    "\n",
    "# categorical_columns = ['procedure', 'nature', 'formePrix', 'ccag',\n",
    "#                                'typeGroupementOperateurs', 'tauxAvance_cat',\n",
    "#                                'codeCPV_3', 'acheteur_tranche_effectif', 'acheteur_categorie']\n",
    "\n",
    "# pipeline = create_pipeline(numerical_columns, binary_columns, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "594ea23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_preproc = pipeline.fit_transform(X_train)\n",
    "# X_train_preproc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "36a4251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "# y_train_cat = to_categorical(y_train)\n",
    "# y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6a71d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_mlp_model(input_dim=220, num_classes=9, use_dropout=True, l2_factor=1e-4):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "#     # Couche 1\n",
    "#     model.add(layers.Dense(\n",
    "#         1028, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.4))\n",
    "\n",
    "#     # Couche 2\n",
    "#     model.add(layers.Dense(\n",
    "#         512, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     # Couche 3\n",
    "#     model.add(layers.Dense(\n",
    "#         256, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.2))\n",
    "\n",
    "#     # Sortie\n",
    "#     model.add(layers.Dense(\n",
    "#         num_classes, activation='softmax',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "\n",
    "#     # Compilation\n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5121e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_mlp_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "833c0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = EarlyStopping(patience=8, restore_best_weights=True)\n",
    "# lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# history = model.fit(\n",
    "#         X_train_preproc, y_train_cat,\n",
    "#         validation_split=0.2,\n",
    "#         batch_size=128,\n",
    "#         epochs=150,\n",
    "#         callbacks=[es, lr_scheduler],\n",
    "#         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19946a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Récupération des données d'entraînement et validation\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# # Création de la figure\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot de l'accuracy\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(acc, label='Accuracy')\n",
    "# plt.plot(val_acc, label='Val Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot de la loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(loss, label='Loss')\n",
    "# plt.plot(val_loss, label='Val Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # Affichage\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c0886821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"modele_montant.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a793e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1028</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">227,188</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1028</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1028</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">526,848</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1028\u001b[0m)           │       \u001b[38;5;34m227,188\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1028\u001b[0m)           │         \u001b[38;5;34m4,112\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1028\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m526,848\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">895,118</span> (3.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m895,118\u001b[0m (3.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">891,526</span> (3.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m891,526\u001b[0m (3.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,592</span> (14.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,592\u001b[0m (14.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimensions\n",
    "input_dim = 220\n",
    "num_classes = 10\n",
    "\n",
    "# Modèle MLP\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "model.add(layers.Dense(1028, activation='relu',))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))  # Sortie pour classification\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # ou 'categorical_crossentropy' si y est one-hot\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "445a8aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 9), output.shape=(None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train_preproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/decp_ml_env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/decp_ml_env/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:669\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    672\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    673\u001b[0m         )\n\u001b[1;32m    675\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[1;32m    676\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 9), output.shape=(None, 10)"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True, min_delta=1e-3)\n",
    "\n",
    "history2 = model.fit(\n",
    "        X_train_preproc, y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        batch_size=32,\n",
    "        epochs=100,\n",
    "        callbacks=[es],\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données d'entraînement et validation\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Création de la figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot de l'accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Accuracy')\n",
    "plt.plot(val_acc, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot de la loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Affichage\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743d328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions\n",
    "input_dim = 220\n",
    "num_classes = 10\n",
    "\n",
    "# Modèle MLP\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "model.add(layers.Dense(1028, activation='relu',))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))  # Sortie pour classification\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # ou 'categorical_crossentropy' si y est one-hot\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Affichage du résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
    "# early_stop = EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97113319",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model.fit(\n",
    "    X_train_preproc, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp_model(input_dim=220, num_classes=10, use_dropout=True):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "    model.add(layers.Dense(1028, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    if use_dropout:\n",
    "        model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    if use_dropout:\n",
    "        model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    if use_dropout:\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',  # or 'sparse_categorical_crossentropy'\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mlp_model(use_dropout=False)\n",
    "\n",
    "history4 = model.fit(\n",
    "    X_train_preproc, y_train_cat,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données d'entraînement et validation\n",
    "acc = history4.history['accuracy']\n",
    "val_acc = history4.history['val_accuracy']\n",
    "loss = history4.history['loss']\n",
    "val_loss = history4.history['val_loss']\n",
    "\n",
    "# Création de la figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot de l'accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc, label='Accuracy')\n",
    "plt.plot(val_acc, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot de la loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss, label='Loss')\n",
    "plt.plot(val_loss, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Affichage\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_mlp_model(input_dim=220, num_classes=10, use_dropout=True, l2_factor=1e-4):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "#     # Couche 1\n",
    "#     model.add(layers.Dense(\n",
    "#         1028, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.5))\n",
    "\n",
    "#     # Couche 2\n",
    "#     model.add(layers.Dense(\n",
    "#         512, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.4))\n",
    "\n",
    "#     # Couche 3\n",
    "#     model.add(layers.Dense(\n",
    "#         256, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     # Sortie\n",
    "#     model.add(layers.Dense(\n",
    "#         num_classes, activation='softmax',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "\n",
    "#     # Compilation\n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f532b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_mlp_model(use_dropout=False)\n",
    "# history5 = model.fit(\n",
    "#     X_train_preproc, y_train_cat,\n",
    "#     validation_split=0.2,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stop, lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.1753 - loss: 2.4798 - val_accuracy: 0.2145 - val_loss: 2.0978 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2096 - loss: 2.1010 - val_accuracy: 0.2074 - val_loss: 2.0562 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2108 - loss: 2.0614 - val_accuracy: 0.2142 - val_loss: 2.0333 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2128 - loss: 2.0376 - val_accuracy: 0.2214 - val_loss: 2.0138 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2185 - loss: 2.0186 - val_accuracy: 0.2202 - val_loss: 2.0169 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2168 - loss: 2.0153 - val_accuracy: 0.2238 - val_loss: 2.0098 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2182 - loss: 2.0122 - val_accuracy: 0.2167 - val_loss: 2.0074 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2204 - loss: 2.0083 - val_accuracy: 0.2229 - val_loss: 2.0044 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2224 - loss: 2.0042 - val_accuracy: 0.2197 - val_loss: 2.0038 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2243 - loss: 2.0030 - val_accuracy: 0.2202 - val_loss: 1.9996 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2221 - loss: 2.0022 - val_accuracy: 0.2258 - val_loss: 1.9945 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2244 - loss: 1.9996 - val_accuracy: 0.2285 - val_loss: 1.9940 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2289 - loss: 1.9935 - val_accuracy: 0.2307 - val_loss: 1.9954 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2282 - loss: 1.9924 - val_accuracy: 0.2263 - val_loss: 1.9945 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2289 - loss: 1.9954 - val_accuracy: 0.2284 - val_loss: 1.9904 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2309 - loss: 1.9911 - val_accuracy: 0.2281 - val_loss: 1.9908 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.2306 - loss: 1.9921 - val_accuracy: 0.2259 - val_loss: 1.9900 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2295 - loss: 1.9892 - val_accuracy: 0.2302 - val_loss: 1.9893 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2331 - loss: 1.9871 - val_accuracy: 0.2311 - val_loss: 1.9870 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2345 - loss: 1.9829 - val_accuracy: 0.2344 - val_loss: 1.9836 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2338 - loss: 1.9878 - val_accuracy: 0.2336 - val_loss: 1.9820 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2370 - loss: 1.9827 - val_accuracy: 0.2351 - val_loss: 1.9859 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2333 - loss: 1.9836 - val_accuracy: 0.2356 - val_loss: 1.9824 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2352 - loss: 1.9840 - val_accuracy: 0.2372 - val_loss: 1.9795 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2344 - loss: 1.9826 - val_accuracy: 0.2350 - val_loss: 1.9841 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2360 - loss: 1.9812 - val_accuracy: 0.2360 - val_loss: 1.9784 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2367 - loss: 1.9786 - val_accuracy: 0.2381 - val_loss: 1.9747 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2367 - loss: 1.9798 - val_accuracy: 0.2356 - val_loss: 1.9792 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2392 - loss: 1.9782 - val_accuracy: 0.2406 - val_loss: 1.9742 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2373 - loss: 1.9747 - val_accuracy: 0.2367 - val_loss: 1.9752 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2391 - loss: 1.9746 - val_accuracy: 0.2356 - val_loss: 1.9761 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m1187/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2377 - loss: 1.9746\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2377 - loss: 1.9746 - val_accuracy: 0.2354 - val_loss: 1.9772 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2423 - loss: 1.9592 - val_accuracy: 0.2463 - val_loss: 1.9548 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2470 - loss: 1.9434 - val_accuracy: 0.2471 - val_loss: 1.9475 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2513 - loss: 1.9378 - val_accuracy: 0.2498 - val_loss: 1.9439 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2523 - loss: 1.9292 - val_accuracy: 0.2505 - val_loss: 1.9417 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2532 - loss: 1.9250 - val_accuracy: 0.2541 - val_loss: 1.9400 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.2562 - loss: 1.9223 - val_accuracy: 0.2499 - val_loss: 1.9383 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2556 - loss: 1.9234 - val_accuracy: 0.2514 - val_loss: 1.9397 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2594 - loss: 1.9193 - val_accuracy: 0.2513 - val_loss: 1.9358 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2641 - loss: 1.9125 - val_accuracy: 0.2506 - val_loss: 1.9366 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2640 - loss: 1.9127 - val_accuracy: 0.2566 - val_loss: 1.9355 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2617 - loss: 1.9108 - val_accuracy: 0.2554 - val_loss: 1.9369 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2630 - loss: 1.9132 - val_accuracy: 0.2550 - val_loss: 1.9319 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2671 - loss: 1.9111 - val_accuracy: 0.2550 - val_loss: 1.9352 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2645 - loss: 1.9111 - val_accuracy: 0.2566 - val_loss: 1.9335 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2659 - loss: 1.9114\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2659 - loss: 1.9114 - val_accuracy: 0.2578 - val_loss: 1.9331 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2754 - loss: 1.8931 - val_accuracy: 0.2615 - val_loss: 1.9206 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2772 - loss: 1.8834 - val_accuracy: 0.2645 - val_loss: 1.9178 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2821 - loss: 1.8751 - val_accuracy: 0.2666 - val_loss: 1.9144 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2813 - loss: 1.8694 - val_accuracy: 0.2668 - val_loss: 1.9144 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.2825 - loss: 1.8682 - val_accuracy: 0.2671 - val_loss: 1.9116 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2863 - loss: 1.8644 - val_accuracy: 0.2704 - val_loss: 1.9107 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2878 - loss: 1.8612 - val_accuracy: 0.2700 - val_loss: 1.9086 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2856 - loss: 1.8624 - val_accuracy: 0.2685 - val_loss: 1.9092 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2895 - loss: 1.8577 - val_accuracy: 0.2715 - val_loss: 1.9045 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2910 - loss: 1.8531 - val_accuracy: 0.2711 - val_loss: 1.9036 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2923 - loss: 1.8551 - val_accuracy: 0.2731 - val_loss: 1.9040 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2918 - loss: 1.8488 - val_accuracy: 0.2709 - val_loss: 1.9039 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2913 - loss: 1.8522 - val_accuracy: 0.2713 - val_loss: 1.9024 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2934 - loss: 1.8482 - val_accuracy: 0.2739 - val_loss: 1.9030 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2911 - loss: 1.8495 - val_accuracy: 0.2757 - val_loss: 1.9031 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m1186/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2944 - loss: 1.8483\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2944 - loss: 1.8484 - val_accuracy: 0.2728 - val_loss: 1.9038 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.2991 - loss: 1.8375 - val_accuracy: 0.2771 - val_loss: 1.8962 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3027 - loss: 1.8259 - val_accuracy: 0.2776 - val_loss: 1.8948 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3045 - loss: 1.8230 - val_accuracy: 0.2816 - val_loss: 1.8945 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3045 - loss: 1.8223 - val_accuracy: 0.2797 - val_loss: 1.8941 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3075 - loss: 1.8198 - val_accuracy: 0.2782 - val_loss: 1.8940 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3065 - loss: 1.8173 - val_accuracy: 0.2819 - val_loss: 1.8918 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3064 - loss: 1.8147 - val_accuracy: 0.2796 - val_loss: 1.8906 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3107 - loss: 1.8128 - val_accuracy: 0.2819 - val_loss: 1.8894 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3092 - loss: 1.8146 - val_accuracy: 0.2808 - val_loss: 1.8883 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3103 - loss: 1.8109 - val_accuracy: 0.2815 - val_loss: 1.8874 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3100 - loss: 1.8107 - val_accuracy: 0.2825 - val_loss: 1.8872 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3119 - loss: 1.8076 - val_accuracy: 0.2842 - val_loss: 1.8868 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3134 - loss: 1.8066 - val_accuracy: 0.2836 - val_loss: 1.8862 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3127 - loss: 1.8055 - val_accuracy: 0.2829 - val_loss: 1.8862 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3149 - loss: 1.8014 - val_accuracy: 0.2858 - val_loss: 1.8841 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3133 - loss: 1.8013 - val_accuracy: 0.2844 - val_loss: 1.8841 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3137 - loss: 1.8027 - val_accuracy: 0.2849 - val_loss: 1.8832 - learning_rate: 1.2500e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3138 - loss: 1.7992 - val_accuracy: 0.2858 - val_loss: 1.8834 - learning_rate: 1.2500e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3160 - loss: 1.7948 - val_accuracy: 0.2847 - val_loss: 1.8823 - learning_rate: 1.2500e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3175 - loss: 1.7952 - val_accuracy: 0.2868 - val_loss: 1.8829 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3167 - loss: 1.7927 - val_accuracy: 0.2859 - val_loss: 1.8832 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m1187/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3185 - loss: 1.7931\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.3185 - loss: 1.7931 - val_accuracy: 0.2875 - val_loss: 1.8824 - learning_rate: 1.2500e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3192 - loss: 1.7916 - val_accuracy: 0.2881 - val_loss: 1.8798 - learning_rate: 6.2500e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3218 - loss: 1.7843 - val_accuracy: 0.2876 - val_loss: 1.8783 - learning_rate: 6.2500e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3225 - loss: 1.7823 - val_accuracy: 0.2892 - val_loss: 1.8776 - learning_rate: 6.2500e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3210 - loss: 1.7815 - val_accuracy: 0.2893 - val_loss: 1.8784 - learning_rate: 6.2500e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3258 - loss: 1.7753 - val_accuracy: 0.2904 - val_loss: 1.8785 - learning_rate: 6.2500e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.3244 - loss: 1.7796 - val_accuracy: 0.2896 - val_loss: 1.8772 - learning_rate: 6.2500e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3239 - loss: 1.7779 - val_accuracy: 0.2887 - val_loss: 1.8767 - learning_rate: 6.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3254 - loss: 1.7726 - val_accuracy: 0.2889 - val_loss: 1.8778 - learning_rate: 6.2500e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3257 - loss: 1.7707 - val_accuracy: 0.2896 - val_loss: 1.8777 - learning_rate: 6.2500e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3262 - loss: 1.7725 - val_accuracy: 0.2916 - val_loss: 1.8760 - learning_rate: 6.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3265 - loss: 1.7698 - val_accuracy: 0.2917 - val_loss: 1.8754 - learning_rate: 6.2500e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3295 - loss: 1.7647 - val_accuracy: 0.2914 - val_loss: 1.8776 - learning_rate: 6.2500e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3281 - loss: 1.7675 - val_accuracy: 0.2918 - val_loss: 1.8762 - learning_rate: 6.2500e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m1189/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3262 - loss: 1.7736\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3262 - loss: 1.7736 - val_accuracy: 0.2914 - val_loss: 1.8763 - learning_rate: 6.2500e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m1191/1191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - accuracy: 0.3269 - loss: 1.7691 - val_accuracy: 0.2927 - val_loss: 1.8761 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "# model = build_mlp_model(use_dropout=True)\n",
    "# history5 = model.fit(\n",
    "#     X_train_preproc, y_train_cat,\n",
    "#     validation_split=0.2,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stop, lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c752f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Récupération des données d'entraînement et validation\n",
    "# acc = history5.history['accuracy']\n",
    "# val_acc = history5.history['val_accuracy']\n",
    "# loss = history5.history['loss']\n",
    "# val_loss = history5.history['val_loss']\n",
    "\n",
    "# # Création de la figure\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot de l'accuracy\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(acc, label='Accuracy')\n",
    "# plt.plot(val_acc, label='Val Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot de la loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(loss, label='Loss')\n",
    "# plt.plot(val_loss, label='Val Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # Affichage\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4e5393da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_mlp_model(use_dropout=False)\n",
    "# history6 = model.fit(\n",
    "#     X_train_preproc, y_train_cat,\n",
    "#     validation_split=0.2,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stop, lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1730ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Récupération des données d'entraînement et validation\n",
    "# acc = history6.history['accuracy']\n",
    "# val_acc = history6.history['val_accuracy']\n",
    "# loss = history6.history['loss']\n",
    "# val_loss = history6.history['val_loss']\n",
    "\n",
    "# # Création de la figure\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot de l'accuracy\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(acc, label='Accuracy')\n",
    "# plt.plot(val_acc, label='Val Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot de la loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(loss, label='Loss')\n",
    "# plt.plot(val_loss, label='Val Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # Affichage\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_mlp_model(input_dim=220, num_classes=9, use_dropout=True, l2_factor=1e-4):\n",
    "#     model = Sequential()\n",
    "#     model.add(Input(shape=(input_dim,)))\n",
    "\n",
    "#     # Couche 1\n",
    "#     model.add(layers.Dense(\n",
    "#         1024, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.4))\n",
    "\n",
    "#     # Couche 2\n",
    "#     model.add(layers.Dense(\n",
    "#         512, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.3))\n",
    "\n",
    "#     # Couche 3\n",
    "#     model.add(layers.Dense(\n",
    "#         256, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.2))\n",
    "#     #couche 4\n",
    "#     model.add(layers.Dense(\n",
    "#         128, activation='relu',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "#     model.add(layers.BatchNormalization())\n",
    "#     if use_dropout:\n",
    "#         model.add(layers.Dropout(0.1))\n",
    "\n",
    "#     # Sortie\n",
    "#     model.add(layers.Dense(\n",
    "#         num_classes, activation='softmax',\n",
    "#         kernel_regularizer=regularizers.l2(l2_factor)\n",
    "#     ))\n",
    "\n",
    "#     # Compilation\n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=['accuracy']\n",
    "#     )\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c42b7482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_mlp_model(use_dropout=False)\n",
    "# history7 = model.fit(\n",
    "#     X_train_preproc, y_train_cat,\n",
    "#     validation_split=0.2,\n",
    "#     batch_size=128,\n",
    "#     epochs=100,\n",
    "#     callbacks=[early_stop, lr_scheduler],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "89be7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Récupération des données d'entraînement et validation\n",
    "# acc = history7.history['accuracy']\n",
    "# val_acc = history7.history['val_accuracy']\n",
    "# loss = history7.history['loss']\n",
    "# val_loss = history7.history['val_loss']\n",
    "\n",
    "# # Création de la figure\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot de l'accuracy\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(acc, label='Accuracy')\n",
    "# plt.plot(val_acc, label='Val Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Plot de la loss\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(loss, label='Loss')\n",
    "# plt.plot(val_loss, label='Val Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# # Affichage\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88430391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decp_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
